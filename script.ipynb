{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Armin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_profiling as pp\n",
    "from IPython.display import display, HTML\n",
    "import pymannkendall as mk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from sklearn.linear_model import Ridge\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_assumptions(features, label, feature_names=None):\n",
    "    \"\"\"\n",
    "    Tests a linear regression on the model to see if assumptions are being met\n",
    "    \"\"\"\n",
    "    display(range(features.shape[1]))\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "    # Setting feature names to x1, x2, x3, etc. if they are not defined\n",
    "    if feature_names is None:\n",
    "        feature_names = ['X'+str(feature+1) for feature in range(features.shape[1])]\n",
    "    \n",
    "    print('Fitting linear regression')\n",
    "    # Multi-threading if the dataset is a size where doing so is beneficial\n",
    "    if features.shape[0] < 100000:\n",
    "        model = LinearRegression(n_jobs=-1)\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "        \n",
    "    model.fit(features, label)\n",
    "    \n",
    "    # Returning linear regression R^2 and coefficients before performing diagnostics\n",
    "    r2 = model.score(features, label)\n",
    "    print()\n",
    "    print('R^2:', r2, '\\n')\n",
    "    print('Coefficients')\n",
    "    print('-------------------------------------')\n",
    "    print('Intercept:', model.intercept_)\n",
    "    \n",
    "    for feature in range(len(model.coef_)):\n",
    "        print('{0}: {1}'.format(feature_names[feature], model.coef_[feature]))\n",
    "\n",
    "    print('\\nPerforming linear regression assumption testing')\n",
    "    \n",
    "    # Creating predictions and calculating residuals for assumption tests\n",
    "    predictions = model.predict(features)\n",
    "    df_results = pd.DataFrame({'Actual': label, 'Predicted': predictions})\n",
    "    df_results['Residuals'] = abs(df_results['Actual']) - abs(df_results['Predicted'])\n",
    "\n",
    "    \n",
    "    def linear_assumption():\n",
    "        \"\"\"\n",
    "        Linearity: Assumes there is a linear relationship between the predictors and\n",
    "                   the response variable. If not, either a polynomial term or another\n",
    "                   algorithm should be used.\n",
    "        \"\"\"\n",
    "        print('\\n=======================================================================================')\n",
    "        print('Assumption 1: Linear Relationship between the Target and the Features')\n",
    "        \n",
    "        print('Checking with a scatter plot of actual vs. predicted. Predictions should follow the diagonal line.')\n",
    "        \n",
    "        # Plotting the actual vs predicted values\n",
    "        sns.lmplot(x='Actual', y='Predicted', data=df_results, fit_reg=False, size=7)\n",
    "        \n",
    "        # Plotting the diagonal line\n",
    "        line_coords = np.arange(df_results.min().min(), df_results.max().max())\n",
    "        plt.plot(line_coords, line_coords,  # X and y points\n",
    "                 color='darkorange', linestyle='--')\n",
    "        plt.title('Actual vs. Predicted')\n",
    "        plt.show()\n",
    "        print('If non-linearity is apparent, consider adding a polynomial term')\n",
    "        \n",
    "        \n",
    "    def normal_errors_assumption(p_value_thresh=0.05):\n",
    "        \"\"\"\n",
    "        Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "        nonlinear transformations of variables may solve this.\n",
    "               \n",
    "        This assumption being violated primarily causes issues with the confidence intervals\n",
    "        \"\"\"\n",
    "        from statsmodels.stats.diagnostic import normal_ad\n",
    "        print('\\n=======================================================================================')\n",
    "        print('Assumption 2: The error terms are normally distributed')\n",
    "        print()\n",
    "    \n",
    "        print('Using the Anderson-Darling test for normal distribution')\n",
    "\n",
    "        # Performing the test on the residuals\n",
    "        p_value = normal_ad(df_results['Residuals'])[1]\n",
    "        print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "    \n",
    "        # Reporting the normality of the residuals\n",
    "        if p_value < p_value_thresh:\n",
    "            print('Residuals are not normally distributed')\n",
    "        else:\n",
    "            print('Residuals are normally distributed')\n",
    "    \n",
    "        # Plotting the residuals distribution\n",
    "        plt.subplots(figsize=(12, 6))\n",
    "        plt.title('Distribution of Residuals')\n",
    "        sns.distplot(df_results['Residuals'])\n",
    "        plt.show()\n",
    "    \n",
    "        print()\n",
    "        if p_value > p_value_thresh:\n",
    "            print('Assumption satisfied')\n",
    "        else:\n",
    "            print('Assumption not satisfied')\n",
    "            print()\n",
    "            print('Confidence intervals will likely be affected')\n",
    "            print('Try performing nonlinear transformations on variables')\n",
    "        \n",
    "        \n",
    "    def multicollinearity_assumption():\n",
    "        \"\"\"\n",
    "        Multicollinearity: Assumes that predictors are not correlated with each other. If there is\n",
    "                           correlation among the predictors, then either remove prepdictors with high\n",
    "                           Variance Inflation Factor (VIF) values or perform dimensionality reduction\n",
    "                           \n",
    "                           This assumption being violated causes issues with interpretability of the \n",
    "                           coefficients and the standard errors of the coefficients.\n",
    "        \"\"\"\n",
    "        print('\\n=======================================================================================')\n",
    "        print('Assumption 3: Little to no multicollinearity among predictors')\n",
    "        \n",
    "        # Plotting the heatmap\n",
    "        plt.figure(figsize = (10,8))\n",
    "        sns.heatmap(pd.DataFrame(features, columns=feature_names).corr(), annot=True)\n",
    "        plt.title('Correlation of Variables')\n",
    "        plt.show()\n",
    "        \n",
    "        print('Variance Inflation Factors (VIF)')\n",
    "        print('> 10: An indication that multicollinearity may be present')\n",
    "        print('> 100: Certain multicollinearity among the variables')\n",
    "        print('-------------------------------------')\n",
    "       \n",
    "        # Gathering the VIF for each variable\n",
    "        VIF = [variance_inflation_factor(features.to_numpy(), i) for i in range(features.to_numpy().shape[1])]\n",
    "        for idx, vif in enumerate(VIF):\n",
    "            print('{0}: {1}'.format(feature_names[idx], vif))\n",
    "        \n",
    "        # Gathering and printing total cases of possible or definite multicollinearity\n",
    "        possible_multicollinearity = sum([1 for vif in VIF if vif > 10])\n",
    "        definite_multicollinearity = sum([1 for vif in VIF if vif > 100])\n",
    "        print()\n",
    "        print('{0} cases of possible multicollinearity'.format(possible_multicollinearity))\n",
    "        print('{0} cases of definite multicollinearity'.format(definite_multicollinearity))\n",
    "        print()\n",
    "\n",
    "        if definite_multicollinearity == 0:\n",
    "            if possible_multicollinearity == 0:\n",
    "                print('Assumption satisfied')\n",
    "            else:\n",
    "                print('Assumption possibly satisfied')\n",
    "                print()\n",
    "                print('Coefficient interpretability may be problematic')\n",
    "                print('Consider removing variables with a high Variance Inflation Factor (VIF)')\n",
    "        else:\n",
    "            print('Assumption not satisfied')\n",
    "            print()\n",
    "            print('Coefficient interpretability will be problematic')\n",
    "            print('Consider removing variables with a high Variance Inflation Factor (VIF)')\n",
    "        \n",
    "        \n",
    "    def autocorrelation_assumption():\n",
    "        \"\"\"\n",
    "        Autocorrelation: Assumes that there is no autocorrelation in the residuals. If there is\n",
    "                         autocorrelation, then there is a pattern that is not explained due to\n",
    "                         the current value being dependent on the previous value.\n",
    "                         This may be resolved by adding a lag variable of either the dependent\n",
    "                         variable or some of the predictors.\n",
    "        \"\"\"\n",
    "        from statsmodels.stats.stattools import durbin_watson\n",
    "        print('\\n=======================================================================================')\n",
    "        print('Assumption 4: No Autocorrelation')\n",
    "        print('\\nPerforming Durbin-Watson Test')\n",
    "        print('Values of 1.5 < d < 2.5 generally show that there is no autocorrelation in the data')\n",
    "        print('0 to 2< is positive autocorrelation')\n",
    "        print('>2 to 4 is negative autocorrelation')\n",
    "        print('-------------------------------------')\n",
    "        durbinWatson = durbin_watson(df_results['Residuals'])\n",
    "        print('Durbin-Watson:', durbinWatson)\n",
    "        if durbinWatson < 1.5:\n",
    "            print('Signs of positive autocorrelation', '\\n')\n",
    "            print('Assumption not satisfied', '\\n')\n",
    "            print('Consider adding lag variables')\n",
    "        elif durbinWatson > 2.5:\n",
    "            print('Signs of negative autocorrelation', '\\n')\n",
    "            print('Assumption not satisfied', '\\n')\n",
    "            print('Consider adding lag variables')\n",
    "        else:\n",
    "            print('Little to no autocorrelation', '\\n')\n",
    "            print('Assumption satisfied')\n",
    "\n",
    "            \n",
    "    def homoscedasticity_assumption():\n",
    "        \"\"\"\n",
    "        Homoscedasticity: Assumes that the errors exhibit constant variance\n",
    "        \"\"\"\n",
    "        print('\\n=======================================================================================')\n",
    "        print('Assumption 5: Homoscedasticity of Error Terms')\n",
    "        print('Residuals should have relative constant variance')\n",
    "        \n",
    "        # Plotting the residuals\n",
    "        plt.subplots(figsize=(12, 6))\n",
    "        ax = plt.subplot(111)  # To remove spines\n",
    "        plt.scatter(x=df_results.index, y=df_results.Residuals, alpha=0.5)\n",
    "        plt.plot(np.repeat(0, df_results.index.max()), color='darkorange', linestyle='--')\n",
    "        ax.spines['right'].set_visible(False)  # Removing the right spine\n",
    "        ax.spines['top'].set_visible(False)  # Removing the top spine\n",
    "        plt.title('Residuals')\n",
    "        plt.show() \n",
    "        print('If heteroscedasticity is apparent, confidence intervals and predictions will be affected')\n",
    "        \n",
    "        \n",
    "    linear_assumption()\n",
    "    normal_errors_assumption()\n",
    "    multicollinearity_assumption()\n",
    "    autocorrelation_assumption()\n",
    "    homoscedasticity_assumption()\n",
    "    plt.show()  \n",
    "    \n",
    "def trend_correlation(features, label):\n",
    "    #print out the correlation between all the variables and the trend\n",
    "    for column in features: \n",
    "        temp = pd.DataFrame(label, columns = ['Trend'])\n",
    "        temp[column] = features[column]\n",
    "        temp.plot(x=column, y='Trend', style='o')  \n",
    "        plt.title('Trend vs variable')  \n",
    "        plt.xlabel(column)  \n",
    "        plt.ylabel('Trend')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda4196c42da9254427a19d4f6d7688b6d0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
